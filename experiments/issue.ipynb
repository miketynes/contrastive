{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Schrier Lab `contrastive` fork issue demonstration\n",
    "\n",
    "Here we will use the Mice Protein Dataset example from the paper to illustrate our issue in extending `contrastive`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "from matplotlib.colors import ListedColormap\n",
    "%matplotlib inline\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# for plotting\n",
    "cmap2 = ListedColormap(['r', 'k'])\n",
    "cmap4 = ListedColormap(['k', 'r', 'g', 'b'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the Mice Protein Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.genfromtxt('datasets/Data_Cortex_Nuclear.csv',delimiter=',',\n",
    "                     skip_header=1,usecols=range(1,78),filling_values=0)\n",
    "classes = np.genfromtxt('datasets/Data_Cortex_Nuclear.csv',delimiter=',',\n",
    "                        skip_header=1,usecols=range(78,81),dtype=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split by contrastive feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_idx_A = np.where((classes[:,-1]==b'S/C') & (classes[:,-2]==b'Saline') & (classes[:,-3]==b'Control'))[0]\n",
    "target_idx_B = np.where((classes[:,-1]==b'S/C') & (classes[:,-2]==b'Saline') & (classes[:,-3]==b'Ts65Dn'))[0]\n",
    "\n",
    "sub_group_labels = len(target_idx_A)*[0] + len(target_idx_B)*[1]\n",
    "target_idx = np.concatenate((target_idx_A,target_idx_B))                                                                          \n",
    "\n",
    "target = data[target_idx]\n",
    "target = (target-np.mean(target,axis=0)) / np.std(target,axis=0) # standardize the dataset\n",
    "\n",
    "background_idx = np.where((classes[:,-1]==b'C/S') & (classes[:,-2]==b'Saline') & (classes[:,-3]==b'Control'))\n",
    "# background_idx = np.where((classes[:,-1]==b'C/S') & (classes[:,-2]==b'Saline') & (classes[:,-3]==b'Ts65Dn'))\n",
    "background = data[background_idx]\n",
    "background = (background-np.mean(background,axis=0)) / np.std(background,axis=0) # standardize the dataset\n",
    "labels = len(background)*[0] + len(target)*[1]\n",
    "data = np.concatenate((background, target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from contrastive import CPCA\n",
    "mdl = CPCA()\n",
    "projected_data = mdl.fit_transform(target, background, active_labels=sub_group_labels, plot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Disussion of issue\n",
    "\n",
    "Above we see some results of CPCA on the Mice Protein dataset. When alpha=789.65, we would expect cPC1 to take account of nearly *all* of the variance in the dataset, and cPC2 to take account of nearly *none* of it. However, based on our extension of the code, this is not what we see: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mdl.bases is where we store information about the cPC basis sets, keyed by the alpha value\n",
    "print(\"Result 1:\\n\")\n",
    "print(mdl.bases[789.65]['variance_ratio'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to our extension of the code, these vectors account for nearly *none* of the variance. That cant be right., \n",
    "\n",
    "Something interesting happens if we store *all* of the cPCs instead of just the top two: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rebuild the cPCA model retaining all cPCs\n",
    "mdl2 = CPCA(n_components=data.shape[1])\n",
    "projected_data = mdl2.fit_transform(target, background, active_labels=sub_group_labels)\n",
    "\n",
    "print(\"Result 2:\\n\")\n",
    "mdl2.bases[789.65]['variance_ratio']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems like in Result 1, our code pulled the cPCS accounting for the *least* variance rather than the *most*. We aren't sure why this would be, but perhaps our understanding of the variable `eig_idx` is subtly flawed. We hope you can help clear this up and let us know where we may have gone astray. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
